# AI情報蓄積

今後のソリューションプロジェクトのの展開のために、基本的な情報や、学ぶべき情報・用語・学習結果等をメモしていく。

## ChatGPT超えの中国AI「DeepSeek-R1」の衝撃

<https://news.yahoo.co.jp/articles/80c04ecf16cbae02d59322c716b62df51ea2dd50>

【引用】

```text
中国のAIスタートアップ「DeepSeek」は2025年1月20日、OpenAIの最新モデル「o1」と同等性能を持つ大規模言語モデル「DeepSeek-R1」をオープンソース（MITライセンス）で公開した。

論文によると、DeepSeek-R1の特筆すべき点は、強化学習（RL：Reinforcement Learning）を駆使し、従来の教師あり学習（SFT：Supervised Fine-Tuning）に頼らず、自律的に思考連鎖（CoT：Chain-of-Thought）を学習する点だ。このアプローチにより、モデルは複雑な問題を解決するための思考の連鎖を探索し、自己検証や振り返り、長い思考の連鎖の生成などの能力を実証しているという。
　
　また、AIが新しい状況やデータに直面したとき、過去の情報がないために適切な判断が難しくなる「コールドスタート問題」を解決するため、AIの学習段階で、あらかじめ新しい状況に関するデータを組み込むことで、AIが初めての状況でも適切に対応できるようにしており、AIの判断や推論の過程がユーザーにとっても理解しやすくなっている。

OpenAIのo1に匹敵
　
　DeepSeek-R1は、さまざまなベンチマークテストで非常に高いパフォーマンスを発揮している。
　
　たとえば、高度な数学の問題を扱う「AIME 2024」では79.8%、さらに、より専門的な数学問題を扱う「MATH-500」では97.3%、ソフトウェア工学関連の「SWE-bench Verified」では49.2%と多くのベンチマークでOpenAIのo1モデルを上回る数値を出している。
　
　また、プログラミングスキルを評価する「Codeforces」では96.3%、一般知識を問う「MMLU」では90.8％とほぼ同等、多段階推論を必要とする「GPQA Diamond」のみ71.5%（o1は75.7％）と下回っているが、総じて多様なタスクにおいてo1モデルに匹敵する汎用性と性能の高さを持っていると言える。
```

これが、今まで主流だったクローズドなAIではなく(OpenAIのo1など)、オープンソースシステムであり、「誰でも運用可能」なところがミソ。

```
蒸留モデルも提供
　
　また、主力モデルであるDeepSeek-R1から知識を抽出し、より小型化した6つの蒸留モデル（パラメータが1.5B、7B、8B、14B、32B、70B）も公開しており、特に32Bおよび70Bのモデルは、OpenAIのo1-miniと同等の性能を持つとされている。
```

## 蒸留モデルとは

モデルの蒸留とは、既存モデルの入力と出力のペアを元に新たなモデルの学習を行い、既存モデルとよく似たモデルを作成することです。 また既存モデルの構造が明らかである場合に、異なるデータを使って再学習したものを派生モデルといいます。

## コールドスタート問題

以下引用

```text
ビジネス環境で起こるコールドスタート問題

AIを活用したアプリケーションやサービスはさまざまですが、大半は「データの学習」を通じて未知の事象に対応するよう設計されています。例えば、あらかじめ「ネコ」や「イヌ」といったラベルが付けられた画像を学習し、未知の画像を認識する画像判別システムや、ユーザーの行動データを学習し、次に求めるアイテムを推測するレコメンドエンジンなどがあります。これらはデータがなければ正確な結果を提供することはできません。

画像判別システムの場合、動物画像などのデータセットで事前に十分学習させた後にシステムをリリースし、コールドスタート問題を回避することが可能です。しかし、企業が自社のECサイトで利用するレコメンドエンジンやパーソナライゼーションシステムの場合、顧客も商品も次々に入れ替わるため、過去のデータ以上に、“いま”の顧客行動データが重要になります。結果として、以下のようなコールドスタート問題が表面化します。

1. サイトの新規ユーザー（初回訪問ユーザー）は、閲覧・購買などの行動履歴が溜まっていないため、高精度のニーズが予測できず、レコメンドの質が低下する。

2. サイトに投入されたばかりの新商品や、ほとんど閲覧されていない“ロングテール商品”は、どのような顧客に見られ、買われているのかのデータが無いため、レコメンドされにくい。
```

## とりあえず手軽にためしてみたいので、お手軽LLMについてDeepseekに聞いてみる

質問

てがるにLLMを試してみたいんですが、Docker起動とかで簡単にハンズオンできるツールみたいなのはありますか? あったら紹介してください。

もちろんあります！Dockerを使えば、LLMを手軽に試すための環境を簡単に構築できます。以下に、ハンズオンしやすいツールやプロジェクトをいくつか紹介します。

---

### **1. Ollama**

Ollamaは、LLMをローカルで簡単に実行するためのツールです。Dockerイメージも提供されており、手軽に試すことができます。

#### **特徴**

- 軽量で使いやすい。
- 複数のLLM（例：LLaMA、GPT-J）をサポート。
- Dockerコンテナとして提供。

#### **使い方**

1. Dockerをインストールします。
2. 以下のコマンドでOllamaを起動：

   ```bash
   docker run -it --rm ollama/ollama
   ```

3. コンテナ内でLLMを実行します。

---

### **2. GPT-Neo (EleutherAI)**

GPT-Neoは、オープンソースのLLMで、Hugging FaceのTransformersライブラリと組み合わせて簡単に使えます。Dockerイメージも提供されています。

#### **特徴**

- GPT-3に似た性能を持つオープンソースモデル。
- Hugging FaceのTransformersと連携。

#### **使い方**

1. Dockerをインストールします。
2. 以下のコマンドでGPT-Neoの環境を構築：

   ```bash
   docker pull huggingface/transformers-pytorch-gpu
   docker run -it --gpus all huggingface/transformers-pytorch-gpu
   ```

3. PythonスクリプトでGPT-Neoを実行：

   ```python
   from transformers import pipeline
   generator = pipeline('text-generation', model='EleutherAI/gpt-neo-1.3B')
   print(generator("Hello, world!"))
   ```

---

### **3. LangChain**

LangChainは、LLMを活用したアプリケーションを構築するためのフレームワークです。Dockerを使った環境構築もサポートされています。

#### **特徴**

- LLMを活用したアプリケーション開発に特化。
- RAG（Retrieval-Augmented Generation）などの高度な機能をサポート。

#### **使い方**

1. Dockerをインストールします。
2. 以下のコマンドでLangChainの環境を構築：

   ```bash
   docker pull langchain/langchain
   docker run -it --rm langchain/langchain
   ```

3. コンテナ内でLangChainを使ったアプリケーションを開発。

---

### **4. Text Generation Web UI**

Text Generation Web UIは、LLMをブラウザから簡単に試せるツールです。Dockerイメージも提供されています。

#### **特徴**

- ブラウザベースのインターフェース。
- 複数のLLM（例：GPT-2、GPT-J）をサポート。

#### **使い方**

1. Dockerをインストールします。
2. 以下のコマンドで環境を構築：

   ```bash
   docker pull oobabooga/text-generation-webui
   docker run -it --rm -p 5000:5000 oobabooga/text-generation-webui
   ```

3. ブラウザで`http://localhost:5000`にアクセスし、LLMを試します。

---

### **5. FastAPI + LLM**

FastAPIを使って、LLMをAPIとして提供するDocker環境を構築することもできます。

#### **特徴**

- LLMをAPIとして利用可能。
- カスタマイズ性が高い。

#### **使い方**

1. Dockerをインストールします。
2. 以下のようなDockerfileを作成：

   ```Dockerfile
   FROM python:3.9-slim
   WORKDIR /app
   COPY requirements.txt .
   RUN pip install -r requirements.txt
   COPY . .
   CMD ["uvicorn", "app:app", "--host", "0.0.0.0", "--port", "8000"]
   ```

3. FastAPIアプリを実装し、LLMを組み込みます。
4. 以下のコマンドでコンテナを起動：

   ```bash
   docker build -t fastapi-llm .
   docker run -it --rm -p 8000:8000 fastapi-llm
   ```

---

### **まとめ**

- **Ollama**や**Text Generation Web UI**は、手軽にLLMを試すのに最適です。
- **GPT-Neo**や**LangChain**は、より高度な使い方や開発をしたい場合に便利です。
- **FastAPI**を使えば、LLMをAPIとして提供するカスタム環境を構築できます。

これらのツールを使えば、Dockerを活用して簡単にLLMを試すことができます。もし具体的な設定や使い方についてさらに詳しく知りたい場合は、ぜひお知らせください！ 😊

## AIに対する利用者の姿勢の調査 2025/01/28 Financial Timesより

デスクワーカーの2/3はAI未利用。

なぜAIを使うのか、使わないのか人間の気持ちを調査。

下記ご種類の人がいる。AIに対する感情を調査。

- Maximalist
  - 夢中になってAIを積極的に利用する人
- Underground
  - AIを積極的に使い重宝しているか、ある種の罪悪感を覚えるため周囲には使っていることを隠す。
  - 他人にずるいことをしていると思われることを心配
- The Rebel
  - AIを脅威のように感じる、反抗的な人。
- The Superfun
  - AIについて興奮しつつ、使わない人。とっかかりが無い状態。
- The Observer
  - まだ様子見をしている人。興味を示しつつ、警戒。これからどうなるか見守っている。

AIを全面的に信頼する、という人は世界に7%。

## Deepseekショック、と言われるほどDeepseekの何がすごいのか

SEARCH: deepseek, deepseekショック, アンドリーセン, ホロウィッツ, nvidia, 低コスト, AI投資, Meta, Alphabet, 中国企業, 中国AI, 中国AI企業

以下日経モーニングFTより 2025/01/29放送

```text
・低コストで性能が高いAIである。
・アンドリーセン&ホロウィッツが評価している
 -> 株式市場に影響が高かった。
・AI投資の中核出会ったアメリカ企業たちと渡り合える会社が出てきた。
・Nvidiaの株価が17%下げ。5900億ドル。日本円にして91兆円。
 -> 28日には9%ほど戻している。
・AI投資が膨らみ続けている。Meta, Alphabet等に940億ドル。全体で2000億ドル/年ほどの投資額。
 -> それに完全に冷や水をかけたのがDeepseek。コストが低い=それほどの性能の半導体が必要ない、という図式か。
・これを機に、投資の調整の始まりになるかも。

[Deepseekの弱点]
・中国の会社なので、国外で顧客を獲得するには一定の困難さがある。今後は中国の国内で展開されることが予想される。
```

以下日経モーニングFT特集より 2025/01/29放送

```text
・Deepseek 中国・杭州市のスタートアップ。2023年創業。
・社長は1985年生まれ。
・社員は「米国帰り」がいない。中国のみのエンジニアで開発。
・Deepseek R-1開発費用はOpenAI等の最先端AI企業よりも格安。
　・ハード: Nbidiaの型落ち中国向け半導体のH800を2048台使って開発。コスト560万ドル。約9億円。
・OpenAIの開発費用と比べると格安である。
・AIの開発に、コスト的障壁がないことを証明した。
・中国のAI人材プールが確実に高まっている。
・OpenAI等のクローズドなAIではなく、オープンソースである。
```

以上の情報から、アメリカ一強だったものが一気に覆される可能性がある。

個人的には、どうしても後追いのものは先駆者よりも良いものを作る傾向があると思うが、これからも先駆者としてのアメリカはしばらくは健在であると思う。

その一方で、先駆者の立ち位置をいつアメリカが失うか、が注目されることになるのではないか。

アメリカがいつまでも逃げ切るか。中国が追い抜くか。はたまた、追い抜いた中国がまたアメリカに追い抜かれるか。

あくまでも「中国のサービス」なので、他国に受け入れられるかどうか、という論点があり、世界的に流行るかどうか、一定のスケールを超えるかどうか、TikTockのように他国から規制をかけられるか、等々、これで中国が覇権をとる、とはまだ判断はできないと思われる。

台湾・尖閣等の質問に関してはセンシティブになっているように学習されている、という検証もある。

## 今後、AIの課題は何か

個人的には、今単にAIバブルがきているだけな気がしていて、それを乗り越えるのためには、一般ユーザーに爆発的に普及するキラーコンテンツ的な利便性をもたらすインターフェースが必要だと思う。

それが何かと言われてすぐに出てこりゃ世話はないが、「極めて手軽に、AIの恩恵を受けられる」ものが出てくる必要がある。上記の通りデスクワークの2/3がAI未利用ということからも、わかる通り、いわんや「デスクワーク以外の人」においてをや、という状態であるので、デスクワークだの肉体労働だのと関係なく、「スマホを持っている人が、極めて便利にAIを使うことができる」ようにならないと今のAIフィーバーは単なるAIバブルで終わるように思う。

一方で、一般ユーザー向けではない高度AIはどんどん進化していくのだと思うので、上記の私の観点は表面的なものに過ぎず、「表面的な生活レベルではなく、社会の根底」にAIが浸透していく可能性もある。そうであるなら、人間がそれを許容できるか、という部分が壁になるだろう。
