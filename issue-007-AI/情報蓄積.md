# AI情報蓄積

今後のソリューションプロジェクトのの展開のために、基本的な情報や、学ぶべき情報・用語・学習結果等をメモしていく。

## ChatGPT超えの中国AI「DeepSeek-R1」の衝撃

<https://news.yahoo.co.jp/articles/80c04ecf16cbae02d59322c716b62df51ea2dd50>

【引用】

```text
中国のAIスタートアップ「DeepSeek」は2025年1月20日、OpenAIの最新モデル「o1」と同等性能を持つ大規模言語モデル「DeepSeek-R1」をオープンソース（MITライセンス）で公開した。

論文によると、DeepSeek-R1の特筆すべき点は、強化学習（RL：Reinforcement Learning）を駆使し、従来の教師あり学習（SFT：Supervised Fine-Tuning）に頼らず、自律的に思考連鎖（CoT：Chain-of-Thought）を学習する点だ。このアプローチにより、モデルは複雑な問題を解決するための思考の連鎖を探索し、自己検証や振り返り、長い思考の連鎖の生成などの能力を実証しているという。
　
　また、AIが新しい状況やデータに直面したとき、過去の情報がないために適切な判断が難しくなる「コールドスタート問題」を解決するため、AIの学習段階で、あらかじめ新しい状況に関するデータを組み込むことで、AIが初めての状況でも適切に対応できるようにしており、AIの判断や推論の過程がユーザーにとっても理解しやすくなっている。

OpenAIのo1に匹敵
　
　DeepSeek-R1は、さまざまなベンチマークテストで非常に高いパフォーマンスを発揮している。
　
　たとえば、高度な数学の問題を扱う「AIME 2024」では79.8%、さらに、より専門的な数学問題を扱う「MATH-500」では97.3%、ソフトウェア工学関連の「SWE-bench Verified」では49.2%と多くのベンチマークでOpenAIのo1モデルを上回る数値を出している。
　
　また、プログラミングスキルを評価する「Codeforces」では96.3%、一般知識を問う「MMLU」では90.8％とほぼ同等、多段階推論を必要とする「GPQA Diamond」のみ71.5%（o1は75.7％）と下回っているが、総じて多様なタスクにおいてo1モデルに匹敵する汎用性と性能の高さを持っていると言える。
```

これが、今まで主流だったクローズドなAIではなく(OpenAIのo1など)、オープンソースシステムであり、「誰でも運用可能」なところがミソ。

```
蒸留モデルも提供
　
　また、主力モデルであるDeepSeek-R1から知識を抽出し、より小型化した6つの蒸留モデル（パラメータが1.5B、7B、8B、14B、32B、70B）も公開しており、特に32Bおよび70Bのモデルは、OpenAIのo1-miniと同等の性能を持つとされている。
```

## 蒸留モデルとは

モデルの蒸留とは、既存モデルの入力と出力のペアを元に新たなモデルの学習を行い、既存モデルとよく似たモデルを作成することです。 また既存モデルの構造が明らかである場合に、異なるデータを使って再学習したものを派生モデルといいます。

## コールドスタート問題

以下引用

```text
ビジネス環境で起こるコールドスタート問題

AIを活用したアプリケーションやサービスはさまざまですが、大半は「データの学習」を通じて未知の事象に対応するよう設計されています。例えば、あらかじめ「ネコ」や「イヌ」といったラベルが付けられた画像を学習し、未知の画像を認識する画像判別システムや、ユーザーの行動データを学習し、次に求めるアイテムを推測するレコメンドエンジンなどがあります。これらはデータがなければ正確な結果を提供することはできません。

画像判別システムの場合、動物画像などのデータセットで事前に十分学習させた後にシステムをリリースし、コールドスタート問題を回避することが可能です。しかし、企業が自社のECサイトで利用するレコメンドエンジンやパーソナライゼーションシステムの場合、顧客も商品も次々に入れ替わるため、過去のデータ以上に、“いま”の顧客行動データが重要になります。結果として、以下のようなコールドスタート問題が表面化します。

1. サイトの新規ユーザー（初回訪問ユーザー）は、閲覧・購買などの行動履歴が溜まっていないため、高精度のニーズが予測できず、レコメンドの質が低下する。

2. サイトに投入されたばかりの新商品や、ほとんど閲覧されていない“ロングテール商品”は、どのような顧客に見られ、買われているのかのデータが無いため、レコメンドされにくい。
```
